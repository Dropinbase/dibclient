
user  application;
worker_processes  auto;

error_log /docker.stderr  crit;
pid        /var/run/nginx.pid;


events {
    # determines how much clients will be served per worker
    # max clients = worker_connections * worker_processes
    # max clients is also limited by the number of socket connections available on the system (~64k)
    worker_connections 4000;

    # optimized to serve many clients with each thread, essential for linux -- for testing environment
    use epoll;

    # accept as many connections as possible, may flood worker connections if set too low -- for testing environment
    multi_accept on;
}


http {
    # cache informations about FDs, frequently accessed files
    # can boost performance, but you need to test those values
    open_file_cache max=200000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;
    
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    access_log off;

    sendfile        on;
    tcp_nopush     on;
    # don't buffer data sent, good for small data bursts in real time
    tcp_nodelay on;

    

    # allow the server to close connection on non responding client, this will free up memory
    reset_timedout_connection on;

    # request timed out -- default 60
    client_body_timeout 60;

    # if client stop responding, free up memory -- default 60
    send_timeout 60;

    # server will close connection after this time -- default 75
    keepalive_timeout 60;

    # number of requests client can make over keep-alive -- for testing environment
    keepalive_requests 100000;

    # Fix for flushing
    fastcgi_keep_conn on;
    fastcgi_buffering off;

    include /etc/nginx/conf.d/*.conf;
}